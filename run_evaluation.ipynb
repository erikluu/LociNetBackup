{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "import src.edge_constructors as edge\n",
    "import src.clustering as clu\n",
    "import src.metrics_fr as fr\n",
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thesis Evaluation\n",
    "\n",
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath, n=None):\n",
    "    assert filepath[-4:] == \".csv\", \"Must be a .csv file\"\n",
    "    data = pd.read_csv(filepath)\n",
    "    if n:\n",
    "        data = data.head(n)\n",
    "\n",
    "    attrs = {\n",
    "        \"titles\": data[\"title\"].tolist(),\n",
    "        \"text\": data[\"text\"].tolist(),\n",
    "        \"tags\": data[\"tags\"].apply(ast.literal_eval).tolist(),\n",
    "        \"ids\": data.index.tolist()\n",
    "    }\n",
    "\n",
    "    if \"simplified_tags\" in data.columns:\n",
    "        attrs[\"simplified_tags\"] = data[\"simplified_tags\"].apply(ast.literal_eval).tolist()\n",
    "\n",
    "    return attrs\n",
    "\n",
    "def load_embeddings(dataset_name, model_names):\n",
    "    embeddings = []\n",
    "    for name in model_names:\n",
    "        embeddings.append(utils.load_from_pickle(f\"embeddings/{dataset_name}_{name}_n10000.pickle\"))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: interview_prep.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"interview_prep\"\n",
    "data = load_data(f\"data/{data_name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding and Similarity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_source</th>\n",
       "      <th>embedding_model</th>\n",
       "      <th>agg_method</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>metric</th>\n",
       "      <th>between_all_nodes</th>\n",
       "      <th>between_shared_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>interview_prep</td>\n",
       "      <td>minilm</td>\n",
       "      <td>mean</td>\n",
       "      <td>cosine</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.684910</td>\n",
       "      <td>0.706979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>interview_prep</td>\n",
       "      <td>minilm</td>\n",
       "      <td>mean</td>\n",
       "      <td>cosine</td>\n",
       "      <td>median</td>\n",
       "      <td>0.674775</td>\n",
       "      <td>0.715765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>interview_prep</td>\n",
       "      <td>minilm</td>\n",
       "      <td>mean</td>\n",
       "      <td>cosine</td>\n",
       "      <td>std_dev</td>\n",
       "      <td>0.069721</td>\n",
       "      <td>0.070315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interview_prep</td>\n",
       "      <td>minilm</td>\n",
       "      <td>mean</td>\n",
       "      <td>soft_cosine</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.641387</td>\n",
       "      <td>0.656642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>interview_prep</td>\n",
       "      <td>minilm</td>\n",
       "      <td>mean</td>\n",
       "      <td>soft_cosine</td>\n",
       "      <td>median</td>\n",
       "      <td>0.644162</td>\n",
       "      <td>0.661419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>interview_prep</td>\n",
       "      <td>minilm</td>\n",
       "      <td>mean</td>\n",
       "      <td>soft_cosine</td>\n",
       "      <td>std_dev</td>\n",
       "      <td>0.126290</td>\n",
       "      <td>0.134193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>interview_prep</td>\n",
       "      <td>minilm</td>\n",
       "      <td>mean</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.537721</td>\n",
       "      <td>0.561980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>interview_prep</td>\n",
       "      <td>minilm</td>\n",
       "      <td>mean</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>median</td>\n",
       "      <td>0.521811</td>\n",
       "      <td>0.566406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>interview_prep</td>\n",
       "      <td>minilm</td>\n",
       "      <td>mean</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>std_dev</td>\n",
       "      <td>0.075639</td>\n",
       "      <td>0.077599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>interview_prep</td>\n",
       "      <td>mpnet</td>\n",
       "      <td>mean</td>\n",
       "      <td>cosine</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.707133</td>\n",
       "      <td>0.725702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      data_source embedding_model agg_method  metric_name   metric  \\\n",
       "0  interview_prep          minilm       mean       cosine     mean   \n",
       "1  interview_prep          minilm       mean       cosine   median   \n",
       "2  interview_prep          minilm       mean       cosine  std_dev   \n",
       "3  interview_prep          minilm       mean  soft_cosine     mean   \n",
       "4  interview_prep          minilm       mean  soft_cosine   median   \n",
       "5  interview_prep          minilm       mean  soft_cosine  std_dev   \n",
       "6  interview_prep          minilm       mean    euclidean     mean   \n",
       "7  interview_prep          minilm       mean    euclidean   median   \n",
       "8  interview_prep          minilm       mean    euclidean  std_dev   \n",
       "0  interview_prep           mpnet       mean       cosine     mean   \n",
       "\n",
       "   between_all_nodes  between_shared_tags  \n",
       "0           0.684910             0.706979  \n",
       "1           0.674775             0.715765  \n",
       "2           0.069721             0.070315  \n",
       "3           0.641387             0.656642  \n",
       "4           0.644162             0.661419  \n",
       "5           0.126290             0.134193  \n",
       "6           0.537721             0.561980  \n",
       "7           0.521811             0.566406  \n",
       "8           0.075639             0.077599  \n",
       "0           0.707133             0.725702  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = fr.get_embedding_similarity_metrics_per_dataset(\"interview_prep\", data[\"tags\"],\n",
    "                                             [\"minilm\", \"mpnet\", \"nomic\", \"bert\", \"specter\", \"word2vec\"],\n",
    "                                             [\"mean\"])\n",
    "df1.to_csv(\"analysis/metric1_interview.csv\")\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Purity, Homogeneity, and Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [1, 2, 5, 10, 15, 20]\n",
    "clustering_methods = {\n",
    "    **{f\"kmeans{k}\": lambda x, k=k: clu.kmeans(x, k) for k in k_values},\n",
    "    **{f\"dbscan_eps{eps}_min{min_samples}\": lambda x, eps=eps, min_samples=min_samples: clu.dbscan(x, eps=eps, min_samples=min_samples) for eps in [0.1, 0.3, 0.5, 0.7, 1.0] for min_samples in [3, 5, 10, 15]},\n",
    "    **{f\"gmm{n_components}\": lambda x, n_components=n_components: clu.gmm(x, n_components) for n_components in k_values},\n",
    "    **{f\"birch{k}\": lambda x, k=k: clu.birch(x, k) for k in k_values}\n",
    "}\n",
    "\n",
    "df2 = fr.compare_cluster_metrics(\"interview_prep\",\n",
    "                                    [\"minilm\", \"mpnet\", \"nomic\", \"bert\", \"specter\", \"word2vec\"],\n",
    "                                    [\"mean\"],\n",
    "                                    clustering_methods, data[\"ids\"], data[\"tags\"], k=2)\n",
    "df2.to_csv(\"analysis/metric2_interview.csv\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Assignment Evaluation: Tag Connectivity and Degree of Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graphs/interview_prep_minilm_cosine_mean_random_edges_kmeans1\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_kmeans2\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_kmeans5\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_dbscan_eps0.1_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_dbscan_eps0.1_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_dbscan_eps0.1_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_dbscan_eps0.1_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_dbscan_eps0.3_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_dbscan_eps0.3_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_dbscan_eps0.3_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_dbscan_eps0.3_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_dbscan_eps0.5_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_dbscan_eps0.5_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_dbscan_eps0.5_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_dbscan_eps0.5_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_dbscan_eps0.7_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_dbscan_eps0.7_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_dbscan_eps0.7_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_dbscan_eps0.7_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_dbscan_eps1.0_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_dbscan_eps1.0_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_dbscan_eps1.0_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_dbscan_eps1.0_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_gmm1\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_gmm2\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_gmm5\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_birch1\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_birch2\n",
      "graphs/interview_prep_minilm_cosine_mean_random_edges_birch5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_kmeans1\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_kmeans2\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_kmeans5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_dbscan_eps0.1_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_dbscan_eps0.1_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_dbscan_eps0.1_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_dbscan_eps0.1_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_dbscan_eps0.3_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_dbscan_eps0.3_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_dbscan_eps0.3_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_dbscan_eps0.3_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_dbscan_eps0.5_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_dbscan_eps0.5_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_dbscan_eps0.5_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_dbscan_eps0.5_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_dbscan_eps0.7_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_dbscan_eps0.7_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_dbscan_eps0.7_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_dbscan_eps0.7_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_dbscan_eps1.0_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_dbscan_eps1.0_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_dbscan_eps1.0_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_dbscan_eps1.0_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_gmm1\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_gmm2\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_gmm5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_birch1\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_birch2\n",
      "graphs/interview_prep_minilm_cosine_mean_knn3_birch5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_kmeans1\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_kmeans2\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_kmeans5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_dbscan_eps0.1_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_dbscan_eps0.1_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_dbscan_eps0.1_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_dbscan_eps0.1_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_dbscan_eps0.3_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_dbscan_eps0.3_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_dbscan_eps0.3_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_dbscan_eps0.3_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_dbscan_eps0.5_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_dbscan_eps0.5_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_dbscan_eps0.5_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_dbscan_eps0.5_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_dbscan_eps0.7_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_dbscan_eps0.7_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_dbscan_eps0.7_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_dbscan_eps0.7_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_dbscan_eps1.0_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_dbscan_eps1.0_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_dbscan_eps1.0_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_dbscan_eps1.0_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_gmm1\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_gmm2\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_gmm5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_birch1\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_birch2\n",
      "graphs/interview_prep_minilm_cosine_mean_knn5_birch5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_kmeans1\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_kmeans2\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_kmeans5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_dbscan_eps0.1_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_dbscan_eps0.1_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_dbscan_eps0.1_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_dbscan_eps0.1_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_dbscan_eps0.3_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_dbscan_eps0.3_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_dbscan_eps0.3_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_dbscan_eps0.3_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_dbscan_eps0.5_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_dbscan_eps0.5_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_dbscan_eps0.5_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_dbscan_eps0.5_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_dbscan_eps0.7_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_dbscan_eps0.7_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_dbscan_eps0.7_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_dbscan_eps0.7_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_dbscan_eps1.0_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_dbscan_eps1.0_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_dbscan_eps1.0_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_dbscan_eps1.0_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_gmm1\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_gmm2\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_gmm5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_birch1\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_birch2\n",
      "graphs/interview_prep_minilm_cosine_mean_knn10_birch5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_kmeans1\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_kmeans2\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_kmeans5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_dbscan_eps0.1_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_dbscan_eps0.1_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_dbscan_eps0.1_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_dbscan_eps0.1_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_dbscan_eps0.3_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_dbscan_eps0.3_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_dbscan_eps0.3_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_dbscan_eps0.3_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_dbscan_eps0.5_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_dbscan_eps0.5_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_dbscan_eps0.5_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_dbscan_eps0.5_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_dbscan_eps0.7_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_dbscan_eps0.7_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_dbscan_eps0.7_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_dbscan_eps0.7_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_dbscan_eps1.0_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_dbscan_eps1.0_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_dbscan_eps1.0_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_dbscan_eps1.0_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_gmm1\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_gmm2\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_gmm5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_birch1\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_birch2\n",
      "graphs/interview_prep_minilm_cosine_mean_knn15_birch5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_kmeans1\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_kmeans2\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_kmeans5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_dbscan_eps0.1_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_dbscan_eps0.1_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_dbscan_eps0.1_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_dbscan_eps0.1_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_dbscan_eps0.3_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_dbscan_eps0.3_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_dbscan_eps0.3_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_dbscan_eps0.3_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_dbscan_eps0.5_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_dbscan_eps0.5_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_dbscan_eps0.5_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_dbscan_eps0.5_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_dbscan_eps0.7_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_dbscan_eps0.7_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_dbscan_eps0.7_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_dbscan_eps0.7_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_dbscan_eps1.0_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_dbscan_eps1.0_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_dbscan_eps1.0_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_dbscan_eps1.0_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_gmm1\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_gmm2\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_gmm5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_birch1\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_birch2\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst3_birch5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_kmeans1\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_kmeans2\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_kmeans5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_dbscan_eps0.1_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_dbscan_eps0.1_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_dbscan_eps0.1_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_dbscan_eps0.1_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_dbscan_eps0.3_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_dbscan_eps0.3_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_dbscan_eps0.3_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_dbscan_eps0.3_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_dbscan_eps0.5_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_dbscan_eps0.5_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_dbscan_eps0.5_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_dbscan_eps0.5_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_dbscan_eps0.7_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_dbscan_eps0.7_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_dbscan_eps0.7_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_dbscan_eps0.7_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_dbscan_eps1.0_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_dbscan_eps1.0_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_dbscan_eps1.0_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_dbscan_eps1.0_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_gmm1\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_gmm2\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_gmm5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_birch1\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_birch2\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst5_birch5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_kmeans1\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_kmeans2\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_kmeans5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_dbscan_eps0.1_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_dbscan_eps0.1_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_dbscan_eps0.1_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_dbscan_eps0.1_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_dbscan_eps0.3_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_dbscan_eps0.3_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_dbscan_eps0.3_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_dbscan_eps0.3_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_dbscan_eps0.5_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_dbscan_eps0.5_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_dbscan_eps0.5_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_dbscan_eps0.5_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_dbscan_eps0.7_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_dbscan_eps0.7_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_dbscan_eps0.7_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_dbscan_eps0.7_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_dbscan_eps1.0_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_dbscan_eps1.0_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_dbscan_eps1.0_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_dbscan_eps1.0_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_gmm1\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_gmm2\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_gmm5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_birch1\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_birch2\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst10_birch5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_kmeans1\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_kmeans2\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_kmeans5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_dbscan_eps0.1_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_dbscan_eps0.1_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_dbscan_eps0.1_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_dbscan_eps0.1_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_dbscan_eps0.3_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_dbscan_eps0.3_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_dbscan_eps0.3_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_dbscan_eps0.3_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_dbscan_eps0.5_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_dbscan_eps0.5_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_dbscan_eps0.5_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_dbscan_eps0.5_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_dbscan_eps0.7_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_dbscan_eps0.7_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_dbscan_eps0.7_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_dbscan_eps0.7_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_dbscan_eps1.0_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_dbscan_eps1.0_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_dbscan_eps1.0_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_dbscan_eps1.0_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_gmm1\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_gmm2\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_gmm5\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_birch1\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_birch2\n",
      "graphs/interview_prep_minilm_cosine_mean_knn_mst15_birch5\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_kmeans1\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_kmeans2\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_kmeans5\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_dbscan_eps0.1_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_dbscan_eps0.1_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_dbscan_eps0.1_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_dbscan_eps0.1_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_dbscan_eps0.3_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_dbscan_eps0.3_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_dbscan_eps0.3_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_dbscan_eps0.3_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_dbscan_eps0.5_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_dbscan_eps0.5_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_dbscan_eps0.5_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_dbscan_eps0.5_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_dbscan_eps0.7_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_dbscan_eps0.7_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_dbscan_eps0.7_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_dbscan_eps0.7_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_dbscan_eps1.0_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_dbscan_eps1.0_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_dbscan_eps1.0_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_dbscan_eps1.0_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_gmm1\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_gmm2\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_gmm5\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_birch1\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_birch2\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.3_birch5\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_kmeans1\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_kmeans2\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_kmeans5\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_dbscan_eps0.1_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_dbscan_eps0.1_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_dbscan_eps0.1_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_dbscan_eps0.1_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_dbscan_eps0.3_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_dbscan_eps0.3_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_dbscan_eps0.3_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_dbscan_eps0.3_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_dbscan_eps0.5_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_dbscan_eps0.5_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_dbscan_eps0.5_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_dbscan_eps0.5_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_dbscan_eps0.7_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_dbscan_eps0.7_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_dbscan_eps0.7_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_dbscan_eps0.7_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_dbscan_eps1.0_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_dbscan_eps1.0_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_dbscan_eps1.0_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_dbscan_eps1.0_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_gmm1\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_gmm2\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_gmm5\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_birch1\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_birch2\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.5_birch5\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_kmeans1\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_kmeans2\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_kmeans5\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_dbscan_eps0.1_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_dbscan_eps0.1_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_dbscan_eps0.1_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_dbscan_eps0.1_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_dbscan_eps0.3_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_dbscan_eps0.3_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_dbscan_eps0.3_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_dbscan_eps0.3_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_dbscan_eps0.5_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_dbscan_eps0.5_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_dbscan_eps0.5_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_dbscan_eps0.5_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_dbscan_eps0.7_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_dbscan_eps0.7_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_dbscan_eps0.7_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_dbscan_eps0.7_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_dbscan_eps1.0_min3\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_dbscan_eps1.0_min5\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_dbscan_eps1.0_min10\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_dbscan_eps1.0_min15\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_gmm1\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_gmm2\n",
      "graphs/interview_prep_minilm_cosine_mean_threshold_0.7_gmm5\n"
     ]
    }
   ],
   "source": [
    "k_values = [1, 2, 5, 50]\n",
    "clustering_methods = {\n",
    "    **{f\"kmeans{k}\": lambda x, k=k: clu.kmeans(x, k) for k in k_values},\n",
    "    **{f\"dbscan_eps{eps}_min{min_samples}\": lambda x, eps=eps, min_samples=min_samples: clu.dbscan(x, eps=eps, min_samples=min_samples) for eps in [0.1, 0.3, 0.5, 0.7, 1.0] for min_samples in [3, 5, 10, 15]},\n",
    "    **{f\"gmm{n_components}\": lambda x, n_components=n_components: clu.gmm(x, n_components) for n_components in k_values},\n",
    "    **{f\"birch{k}\": lambda x, k=k: clu.birch(x, k) for k in k_values}\n",
    "}\n",
    "\n",
    "edge_connector_methods = {\n",
    "    \"random_edges\": lambda sim_mat, document_ids: edge.random_edges(sim_mat, document_ids, num_edges_per_node=5),\n",
    "    **{f\"knn{k}\": lambda sim_mat, document_ids, k=k: edge.knn(sim_mat, document_ids, k) for k in [3, 5, 10, 15]},\n",
    "    **{f\"knn_mst{k}\": lambda sim_mat, document_ids, k=k: edge.knn_mst(sim_mat, document_ids, k) for k in [3, 5, 10, 15]},\n",
    "    **{f\"threshold_{threshold}\": lambda sim_mat, document_ids, threshold=threshold: edge.threshold_based_edge_assignment(sim_mat, document_ids, threshold) for threshold in [0.3, 0.5, 0.7, 0.9]},\n",
    "    **{f\"mutual_knn{k}\": lambda sim_mat, document_ids, k=k: edge.mutual_knn_edge_assignment(sim_mat, document_ids, k) for k in [3, 5, 10, 15]},\n",
    "    **{f\"spectral_clustering{n_clusters}\": lambda sim_mat, document_ids, n_clusters=n_clusters: edge.spectral_clustering_edge_assignment(sim_mat, document_ids, n_clusters) for n_clusters in [2, 3, 5, 10]}\n",
    "}\n",
    "\n",
    "df3 = fr.compare_edge_assignment_metrics(\"interview_prep\",\n",
    "                                        [\"minilm\", \"mpnet\", \"nomic\", \"bert\", \"specter\", \"word2vec\"],\n",
    "                                        [\"mean\"],\n",
    "                                        clustering_methods,\n",
    "                                        edge_connector_methods, data[\"ids\"], data[\"tags\"], data[\"titles\"], max_depth=3)\n",
    "df3.to_csv(\"analysis/metric3_interview.csv\")\n",
    "df3.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: Medium (n=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"medium1k\"\n",
    "data = load_data(f\"data/{data_name}.csv\", n=2000)\n",
    "ids = data[\"ids\"]\n",
    "titles = data[\"titles\"]\n",
    "tags = data[\"simplified_tags\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding and Similarity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df1 \u001b[38;5;241m=\u001b[39m \u001b[43mfr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_embedding_similarity_metrics_per_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmedium1k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mminilm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmpnet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnomic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbert\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspecter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mword2vec\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m df1\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manalysis/metric1_medium1k.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m df1\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Poly/Thesis/LociNet/src/metrics_fr.py:88\u001b[0m, in \u001b[0;36mget_embedding_similarity_metrics_per_dataset\u001b[0;34m(dataset_name, dataset_tags, model_names, agg_methods)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_names:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m agg_method \u001b[38;5;129;01min\u001b[39;00m agg_methods:\n\u001b[0;32m---> 88\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membeddings/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43magg_method\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_n10000.pickle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m5000\u001b[39m]\n\u001b[1;32m     89\u001b[0m         cosine_sim, soft_cosine_sim, euclidean_sim \u001b[38;5;241m=\u001b[39m sim\u001b[38;5;241m.\u001b[39mget_all_similarities(embeddings)\n\u001b[1;32m     90\u001b[0m         dataframes\u001b[38;5;241m.\u001b[39mappend(calculate_embedding_metrics_for_all(cosine_sim, soft_cosine_sim, euclidean_sim,\n\u001b[1;32m     91\u001b[0m                                         dataset_tags, model_name, dataset_name, agg_method))\n",
      "File \u001b[0;32m~/Documents/Poly/Thesis/LociNet/src/utils.py:81\u001b[0m, in \u001b[0;36mload_from_pickle\u001b[0;34m(filename)\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "df1 = fr.get_embedding_similarity_metrics_per_dataset(\"medium1k\", tags,\n",
    "                                             [\"minilm\", \"mpnet\", \"nomic\", \"bert\", \"specter\", \"word2vec\"],\n",
    "                                             [\"mean\"])\n",
    "df1.to_csv(\"analysis/metric1_medium1k.csv\")\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = fr.get_embedding_similarity_metrics_per_dataset(\"medium1k\", tags,\n",
    "#                                              [\"mpnet\", \"nomic\", \"bert\", \"specter\", \"word2vec\"],\n",
    "#                                              [\"mean\"])\n",
    "# df1.to_csv(\"analysis/metric1_medium1k_rest.csv\")\n",
    "# df1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m df_minilm \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manalysis/metric1_medium1k_minilm.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m df_rest \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manalysis/metric1_medium1k_rest.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m df_metric1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_minilm, df_rest])\n\u001b[1;32m      5\u001b[0m df_metric1\u001b[38;5;241m.\u001b[39mcolumns\n",
      "File \u001b[0;32m~/Documents/Poly/Thesis/LociNet/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Poly/Thesis/LociNet/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Documents/Poly/Thesis/LociNet/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Poly/Thesis/LociNet/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Poly/Thesis/LociNet/.venv/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32mparsers.pyx:581\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "df_minilm = pd.read_csv(\"analysis/metric1_medium1k_minilm.csv\")\n",
    "df_rest = pd.read_csv(\"analysis/metric1_medium1k_rest.csv\")\n",
    "\n",
    "df_metric1 = pd.concat([df_minilm, df_rest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_metric1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_metric1\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_metric1' is not defined"
     ]
    }
   ],
   "source": [
    "df_metric1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Purity, Homogeneity, and Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [1, 2, 5, 10, 15, 50, 100]\n",
    "clustering_methods = {\n",
    "    **{f\"kmeans{k}\": lambda x, k=k: clu.kmeans(x, k) for k in k_values},\n",
    "    **{f\"dbscan_eps{eps}_min{min_samples}\": lambda x, eps=eps, min_samples=min_samples: clu.dbscan(x, eps=eps, min_samples=min_samples) for eps in [0.1, 0.3, 0.5, 0.7, 1.0] for min_samples in [3, 5, 10, 15]},\n",
    "    **{f\"gmm{n_components}\": lambda x, n_components=n_components: clu.gmm(x, n_components) for n_components in k_values},\n",
    "    **{f\"birch{k}\": lambda x, k=k: clu.birch(x, k) for k in k_values}\n",
    "}\n",
    "\n",
    "# df2 = fr.compare_cluster_metrics(\"medium1k\",\n",
    "#                                     [\"minilm\", \"mpnet\", \"nomic\", \"bert\", \"specter\", \"word2vec\"],\n",
    "#                                     [\"mean\"],\n",
    "#                                     clustering_methods,\n",
    "#                                     ids, tags, k=2)\n",
    "\n",
    "# df2.to_csv(\"analysis/metric2_medium1k.csv\")\n",
    "# df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = fr.compare_cluster_metrics(\"medium1k\",\n",
    "                                    [\"minilm\"],\n",
    "                                    [\"mean\"],\n",
    "                                    clustering_methods,\n",
    "                                    ids, tags, k=15)\n",
    "\n",
    "df2.to_csv(\"analysis/metric2_medium1k_minilm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = fr.compare_cluster_metrics(\"medium1k\",\n",
    "                                    [\"specter\"],\n",
    "                                    [\"mean\"],\n",
    "                                    clustering_methods,\n",
    "                                    ids, tags, k=15)\n",
    "\n",
    "\n",
    "df2.to_csv(\"analysis/metric2_medium1k_specter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = fr.compare_cluster_metrics(\"medium1k\",\n",
    "                                    [\"word2vec\"],\n",
    "                                    [\"mean\"],\n",
    "                                    clustering_methods,\n",
    "                                    ids, tags, k=15)\n",
    "\n",
    "df2.to_csv(\"analysis/metric2_medium1k_word2vec.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Found array with 1 sample(s) (shape=(1, 768)) while a minimum of 2 is required by AgglomerativeClustering.\n",
      "Skipping bert, mean, birch1 due to insufficient samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erikluu/Documents/Poly/Thesis/LociNet/.venv/lib/python3.11/site-packages/sklearn/cluster/_birch.py:725: ConvergenceWarning: Number of subclusters found (1) by BIRCH is less than (2). Decrease the threshold.\n",
      "  warnings.warn(\n",
      "/Users/erikluu/Documents/Poly/Thesis/LociNet/.venv/lib/python3.11/site-packages/sklearn/cluster/_birch.py:725: ConvergenceWarning: Number of subclusters found (1) by BIRCH is less than (5). Decrease the threshold.\n",
      "  warnings.warn(\n",
      "/Users/erikluu/Documents/Poly/Thesis/LociNet/.venv/lib/python3.11/site-packages/sklearn/cluster/_birch.py:725: ConvergenceWarning: Number of subclusters found (1) by BIRCH is less than (10). Decrease the threshold.\n",
      "  warnings.warn(\n",
      "/Users/erikluu/Documents/Poly/Thesis/LociNet/.venv/lib/python3.11/site-packages/sklearn/cluster/_birch.py:725: ConvergenceWarning: Number of subclusters found (1) by BIRCH is less than (15). Decrease the threshold.\n",
      "  warnings.warn(\n",
      "/Users/erikluu/Documents/Poly/Thesis/LociNet/.venv/lib/python3.11/site-packages/sklearn/cluster/_birch.py:725: ConvergenceWarning: Number of subclusters found (1) by BIRCH is less than (50). Decrease the threshold.\n",
      "  warnings.warn(\n",
      "/Users/erikluu/Documents/Poly/Thesis/LociNet/.venv/lib/python3.11/site-packages/sklearn/cluster/_birch.py:725: ConvergenceWarning: Number of subclusters found (1) by BIRCH is less than (100). Decrease the threshold.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df2 = fr.compare_cluster_metrics(\"medium1k\",\n",
    "                                    [\"bert\"],\n",
    "                                    [\"mean\"],\n",
    "                                    clustering_methods,\n",
    "                                    ids, tags, k=15)\n",
    "\n",
    "df2.to_csv(\"analysis/metric2_medium1k_bert.csv\") # run again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = fr.compare_cluster_metrics(\"medium1k\",\n",
    "                                    [\"nomic\"],\n",
    "                                    [\"mean\"],\n",
    "                                    clustering_methods,\n",
    "                                    ids, tags, k=15)\n",
    "\n",
    "df2.to_csv(\"analysis/metric2_medium1k_nomic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = fr.compare_cluster_metrics(\"medium1k\",\n",
    "                                    [\"mpnet\"],\n",
    "                                    [\"mean\"],\n",
    "                                    clustering_methods,\n",
    "                                    ids, tags, k=15)\n",
    "\n",
    "df2.to_csv(\"analysis/metric2_medium1k_mpnet.csv\") # run again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Assignment Evaluation: Tag Connectivity and Degree of Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [1, 2, 5, 10, 15, 20, 30, 40, 50, 65, 80, 100, 120, 150]\n",
    "threshold_values = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "clustering_methods = {\n",
    "    **{f\"kmeans{k}\": lambda x, k=k: clu.kmeans(x, k) for k in k_values},\n",
    "    **{f\"dbscan_eps{eps}_min{min_samples}\": lambda x, eps=eps, min_samples=min_samples: clu.dbscan(x, eps=eps, min_samples=min_samples) for eps in [0.1, 0.3, 0.5, 0.7, 1.0] for min_samples in [3, 5, 10, 15]},\n",
    "    **{f\"gmm{n_components}\": lambda x, n_components=n_components: clu.gmm(x, n_components) for n_components in k_values},\n",
    "    **{f\"birch{k}\": lambda x, k=k: clu.birch(x, k) for k in k_values}\n",
    "}\n",
    "\n",
    "edge_assignment_methods = {\n",
    "    **{f\"knn{k}\": lambda sim_mat, ids, k=k: edge.knn(sim_mat, ids, k) for k in k_values},\n",
    "    **{f\"knn_mst{k}\": lambda sim_mat, ids, k=k: edge.knn_mst(sim_mat, ids, k) for k in k_values},\n",
    "    **{f\"threshold{threshold}\": lambda sim_mat, ids, threshold=threshold: edge.threshold_based_edge_assignment(sim_mat, ids, threshold) for threshold in threshold_values},\n",
    "    **{f\"mutual_knn{k}\": lambda sim_mat, ids, k=k: edge.mutual_knn_edge_assignment(sim_mat, ids, k) for k in k_values},\n",
    "    **{f\"spectral{n_clusters}\": lambda sim_mat, ids, n_clusters=n_clusters: edge.spectral_clustering_edge_assignment(sim_mat, ids, n_clusters) for n_clusters in k_values}\n",
    "}\n",
    "\n",
    "df3 = fr.compare_edge_assignment_metrics(\"interview_prep\",\n",
    "                                        [\"minilm\", \"mpnet\", \"nomic\", \"bert\", \"specter\", \"word2vec\"],\n",
    "                                        [\"mean\"],\n",
    "                                        clustering_methods,\n",
    "                                        edge_assignment_methods,\n",
    "                                        ids, tags, titles, max_depth=3)\n",
    "\n",
    "df3.to_csv(\"analysis/metric3_medium1k.csv\")\n",
    "print(df3.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_values = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "edge_assignment_methods = {\n",
    "    **{f\"random{k}\": lambda x, k=k: edge.random_edges(x, ids, k) for k in k_values},\n",
    "    **{f\"knn{k}\": lambda sim_mat, ids, k=k: edge.knn(sim_mat, ids, k) for k in k_values},\n",
    "    **{f\"knn_mst{k}\": lambda sim_mat, ids, k=k: edge.knn_mst(sim_mat, ids, k) for k in k_values},\n",
    "    **{f\"threshold{threshold}\": lambda sim_mat, ids, threshold=threshold: edge.threshold_based_edge_assignment(sim_mat, ids, threshold) for threshold in threshold_values},\n",
    "    **{f\"mutual_knn{k}\": lambda sim_mat, ids, k=k: edge.mutual_knn_edge_assignment(sim_mat, ids, k) for k in k_values},\n",
    "    **{f\"spectral{n_clusters}\": lambda sim_mat, ids, n_clusters=n_clusters: edge.spectral_clustering_edge_assignment(sim_mat, ids, n_clusters) for n_clusters in k_values}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df3 \u001b[38;5;241m=\u001b[39m \u001b[43mfr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompare_edge_assignment_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmedium1k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mminilm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mclustering_methods\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43medge_assignment_methods\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m df3\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manalysis/metric3_medium1k_minilm.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Poly/Thesis/LociNet/src/metrics_fr.py:400\u001b[0m, in \u001b[0;36mcompare_edge_assignment_metrics\u001b[0;34m(dataset_name, embedding_models, agg_methods, clusterer_functions, edge_constructor_functions, ids, tags, titles, max_depth)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agg_method \u001b[38;5;129;01min\u001b[39;00m agg_methods:\n\u001b[1;32m    399\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mload_from_pickle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedding_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00magg_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_n10000.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m)[:\u001b[38;5;241m2000\u001b[39m]\n\u001b[0;32m--> 400\u001b[0m     cosine_sim, soft_cosine_sim, euclidean_sim \u001b[38;5;241m=\u001b[39m \u001b[43msim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_all_similarities\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sim_mat, sim_metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m([cosine_sim, soft_cosine_sim, euclidean_sim], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoft_cosine\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m edge_name, edge_f \u001b[38;5;129;01min\u001b[39;00m edge_constructor_functions\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/Documents/Poly/Thesis/LociNet/src/similarity.py:107\u001b[0m, in \u001b[0;36mget_all_similarities\u001b[0;34m(embeddings, sigma)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_all_similarities\u001b[39m(embeddings, sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m):\n\u001b[1;32m    106\u001b[0m     cosine_similarity \u001b[38;5;241m=\u001b[39m batch_similarity_scores(embeddings, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 107\u001b[0m     soft_cosine_similarity_2 \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_similarity_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msoft_cosine\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     euclidean_similarity \u001b[38;5;241m=\u001b[39m batch_similarity_scores(embeddings, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m\"\u001b[39m, sigma\u001b[38;5;241m=\u001b[39msigma)\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cosine_similarity, soft_cosine_similarity_2, euclidean_similarity\n",
      "File \u001b[0;32m~/Documents/Poly/Thesis/LociNet/src/similarity.py:88\u001b[0m, in \u001b[0;36mbatch_similarity_scores\u001b[0;34m(matrix, metric, batch_size, sigma)\u001b[0m\n\u001b[1;32m     85\u001b[0m batch1 \u001b[38;5;241m=\u001b[39m matrix[j:j \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_similarity_matrix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     batch_similarity_matrix \u001b[38;5;241m=\u001b[39m \u001b[43msimilarity_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_similarity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     batch_batch_similarity_matrix \u001b[38;5;241m=\u001b[39m similarity_scores(batch0, batch1, metric, feature_similarity, sigma)\n",
      "File \u001b[0;32m~/Documents/Poly/Thesis/LociNet/src/similarity.py:70\u001b[0m, in \u001b[0;36msimilarity_scores\u001b[0;34m(batch0, batch1, metric, feature_similarity, sigma)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature_similarity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature similarity matrix must be provided for soft cosine similarity\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transform_similarity(\u001b[43msoft_cosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_similarity\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown metric: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Poly/Thesis/LociNet/src/similarity.py:52\u001b[0m, in \u001b[0;36msoft_cosine_similarity\u001b[0;34m(batch0, batch1, feature_similarity)\u001b[0m\n\u001b[1;32m     49\u001b[0m         s \u001b[38;5;241m=\u001b[39m feature_similarity  \u001b[38;5;66;03m# Shape: (N, N)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m         numerator \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m@\u001b[39m (s \u001b[38;5;241m@\u001b[39m b\u001b[38;5;241m.\u001b[39mt())\n\u001b[0;32m---> 52\u001b[0m         denominator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt((a \u001b[38;5;241m@\u001b[39m (s \u001b[38;5;241m@\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)) \u001b[38;5;241m*\u001b[39m (b \u001b[38;5;241m@\u001b[39m (s \u001b[38;5;241m@\u001b[39m b\u001b[38;5;241m.\u001b[39mt())))\n\u001b[1;32m     53\u001b[0m         result[i, j] \u001b[38;5;241m=\u001b[39m numerator \u001b[38;5;241m/\u001b[39m denominator\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df3 = fr.compare_edge_assignment_metrics(\"medium1k\",\n",
    "                                        [\"minilm\"],\n",
    "                                        [\"mean\"],\n",
    "                                        clustering_methods,\n",
    "                                        edge_assignment_methods,\n",
    "                                        ids, tags, titles, max_depth=8)\n",
    "\n",
    "df3.to_csv(\"analysis/metric3_medium1k_minilm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df3 = fr.compare_edge_assignment_metrics(\"medium1k\",\n",
    "                                        [\"specter\"],\n",
    "                                        [\"mean\"],\n",
    "                                        clustering_methods,\n",
    "                                        edge_assignment_methods,\n",
    "                                        ids, tags, titles, max_depth=8)\n",
    "\n",
    "df3.to_csv(\"analysis/metric3_medium1k_specter.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df3 = fr.compare_edge_assignment_metrics(\"medium1k\",\n",
    "                                        [\"word2vec\"],\n",
    "                                        [\"mean\"],\n",
    "                                        clustering_methods,\n",
    "                                        edge_assignment_methods,\n",
    "                                        ids, tags, titles, max_depth=8)\n",
    "\n",
    "df3.to_csv(\"analysis/metric3_medium1k_word2vec.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df3 = fr.compare_edge_assignment_metrics(\"medium1k\",\n",
    "                                        [\"bert\"],\n",
    "                                        [\"mean\"],\n",
    "                                        clustering_methods,\n",
    "                                        edge_assignment_methods,\n",
    "                                        ids, tags, titles, max_depth=8)\n",
    "\n",
    "df3.to_csv(\"analysis/metric3_medium1k_bert.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df3 = fr.compare_edge_assignment_metrics(\"medium1k\",\n",
    "                                        [\"nomic\"],\n",
    "                                        [\"mean\"],\n",
    "                                        clustering_methods,\n",
    "                                        edge_assignment_methods,\n",
    "                                        ids, tags, titles, max_depth=8)\n",
    "\n",
    "df3.to_csv(\"analysis/metric3_medium1k_nomic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df3 = fr.compare_edge_assignment_metrics(\"medium1k\",\n",
    "                                        [\"mpnet\"],\n",
    "                                        [\"mean\"],\n",
    "                                        clustering_methods,\n",
    "                                        edge_assignment_methods,\n",
    "                                        ids, tags, titles, max_depth=8)\n",
    "\n",
    "df3.to_csv(\"analysis/metric3_medium1k_mpnet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# k_values = [1, 2, 5, 10, 15, 20, 30, 40, 50, 65, 80, 100, 120, 150]\n",
    "\n",
    "# clustering_methods = {\n",
    "#     **{f\"kmeans{k}\": lambda x, k=k: clu.kmeans(x, k) for k in k_values},\n",
    "#     **{f\"dbscan_eps{eps}_min{min_samples}\": lambda x, eps=eps, min_samples=min_samples: clu.dbscan(x, eps=eps, min_samples=min_samples) for eps in [0.1, 0.3, 0.5, 0.7, 1.0] for min_samples in [3, 5, 10, 15]},\n",
    "#     **{f\"gmm{n_components}\": lambda x, n_components=n_components: clu.gmm(x, n_components) for n_components in k_values},\n",
    "#     **{f\"birch{k}\": lambda x, k=k: clu.birch(x, k) for k in k_values}\n",
    "# }\n",
    "\n",
    "# df2 = fr.compare_cluster_metrics(\"medium1k\",\n",
    "#                                     [\"minilm\", \"mpnet\", \"nomic\", \"bert\", \"specter\", \"word2vec\"],\n",
    "#                                     [\"mean\"],\n",
    "#                                     clustering_methods,\n",
    "#                                     ids, tags, k=15)\n",
    "\n",
    "# df2.to_csv(\"analysis/metric2_medium1k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# k_values = [1, 2, 5, 10, 15, 20, 30, 40, 50, 65, 80, 100, 120, 150]\n",
    "# threshold_values = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "# clustering_methods = {\n",
    "#     **{f\"kmeans{k}\": lambda x, k=k: clu.kmeans(x, k) for k in k_values},\n",
    "#     **{f\"dbscan_eps{eps}_min{min_samples}\": lambda x, eps=eps, min_samples=min_samples: clu.dbscan(x, eps=eps, min_samples=min_samples) for eps in [0.1, 0.3, 0.5, 0.7, 1.0] for min_samples in [3, 5, 10, 15]},\n",
    "#     **{f\"gmm{n_components}\": lambda x, n_components=n_components: clu.gmm(x, n_components) for n_components in k_values},\n",
    "#     **{f\"birch{k}\": lambda x, k=k: clu.birch(x, k) for k in k_values}\n",
    "# }\n",
    "\n",
    "# edge_assignment_methods = {\n",
    "#     **{f\"knn{k}\": lambda sim_mat, ids, k=k: edge.knn(sim_mat, ids, k) for k in k_values},\n",
    "#     **{f\"knn_mst{k}\": lambda sim_mat, ids, k=k: edge.knn_mst(sim_mat, ids, k) for k in k_values},\n",
    "#     **{f\"threshold{threshold}\": lambda sim_mat, ids, threshold=threshold: edge.threshold_based_edge_assignment(sim_mat, ids, threshold) for threshold in threshold_values},\n",
    "#     **{f\"mutual_knn{k}\": lambda sim_mat, ids, k=k: edge.mutual_knn_edge_assignment(sim_mat, ids, k) for k in k_values},\n",
    "#     **{f\"spectral{n_clusters}\": lambda sim_mat, ids, n_clusters=n_clusters: edge.spectral_clustering_edge_assignment(sim_mat, ids, n_clusters) for n_clusters in k_values}\n",
    "# }\n",
    "\n",
    "# df3 = fr.compare_edge_assignment_metrics(\"interview_prep\",\n",
    "#                                         [\"minilm\", \"mpnet\", \"nomic\", \"bert\", \"specter\", \"word2vec\"],\n",
    "#                                         [\"mean\"],\n",
    "#                                         clustering_methods,\n",
    "#                                         edge_assignment_methods,\n",
    "#                                         ids, tags, titles, max_depth=8)\n",
    "\n",
    "# df3.to_csv(\"analysis/metric3_medium1k.csv\")\n",
    "# df3.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
