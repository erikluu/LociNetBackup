{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erikluu/Desktop/LociNet-main/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Taichi] version 1.7.1, llvm 15.0.7, commit 0f143b2f, osx, python 3.11.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 05/29/24 18:22:36.180 117979] [shell.py:_shell_pop_print@23] Graphical python shell detected, using wrapped sys.stdout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Taichi] Starting on arch=metal\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import src.embeddings as emb\n",
    "import src.similarity as sim\n",
    "import src.metrics_fr as met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath, n=None):\n",
    "    assert filepath[-4:] == \".csv\", \"Must be a .csv file\"\n",
    "    data = pd.read_csv(filepath)\n",
    "    if n:\n",
    "        data = data.head(n)\n",
    "\n",
    "    attrs = {\n",
    "        \"titles\": data[\"title\"].tolist(),\n",
    "        \"text\": data[\"abstract\"].tolist(),\n",
    "        \"tags\": data[\"tags\"].apply(ast.literal_eval).tolist(),\n",
    "        \"ids\": data.index.tolist()\n",
    "    }\n",
    "\n",
    "    if \"simplified_tags\" in data.columns:\n",
    "        attrs[\"simplified_tags\"] = data[\"simplified_tags\"].apply(ast.literal_eval).tolist()\n",
    "\n",
    "    return attrs\n",
    "\n",
    "\n",
    "def save_to_pickle(object, filename):\n",
    "    pickle.dump(object, open(filename, 'wb'))\n",
    "\n",
    "\n",
    "def load_from_pickle(filename):\n",
    "    return pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"medium1k\"\n",
    "data = load_data(f\"data/{data_name}.csv\", 2000)\n",
    "text = data[\"text\"]\n",
    "tags = data[\"simplified_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"word2vec\"\n",
    "word2vec_embeddings = emb.process_embeddings(text, model_name)\n",
    "save_to_pickle(word2vec_embeddings, \"embeddings/medium1k_word2vec_mean_n2000.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"minilm\"\n",
    "minilm_embeddings = emb.process_embeddings(text, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_pickle(minilm_embeddings, \"embeddings/medium1k_minilm_n10000.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mpnet\"\n",
    "mpnet_embeddings = emb.process_embeddings(text, model_name)\n",
    "cosine_sim, soft_cosine_sim, euclidean_sim = sim.get_all_similarities(mpnet_embeddings)\n",
    "all_mpnet_df = met.calculate_embedding_metrics_for_all(cosine_sim, soft_cosine_sim, euclidean_sim,\n",
    "                                        tags, model_name, data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_pickle(mpnet_embeddings, \"embeddings/medium1k_mpnet_n10000.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"nomic\"\n",
    "nomic_embeddings = emb.process_embeddings(text, model_name)\n",
    "cosine_sim, soft_cosine_sim, euclidean_sim = sim.get_all_similarities(nomic_embeddings)\n",
    "nomic_df = met.calculate_embedding_metrics_for_all(cosine_sim, soft_cosine_sim, euclidean_sim,\n",
    "                                        tags, model_name, data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_pickle(nomic_embeddings, \"embeddings/medium1k_nomic_n10000.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert\"\n",
    "bert_embeddings = emb.process_embeddings(text, model_name)\n",
    "cosine_sim, soft_cosine_sim, euclidean_sim = sim.get_all_similarities(bert_embeddings)\n",
    "bert_df = met.calculate_embedding_metrics_for_all(cosine_sim, soft_cosine_sim, euclidean_sim,\n",
    "                                        tags, model_name, data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_pickle(bert_embeddings, \"embeddings/medium1k_bert_n10000.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"specter\"\n",
    "specter_embeddings = emb.process_embeddings(text, model_name)\n",
    "cosine_sim, soft_cosine_sim, euclidean_sim = sim.get_all_similarities(specter_embeddings)\n",
    "specter_df = met.calculate_embedding_metrics_for_all(cosine_sim, soft_cosine_sim, euclidean_sim,\n",
    "                                        tags, model_name, data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_pickle(specter_embeddings, \"embeddings/medium1k_specter_n10000.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARXIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/16/w2tjk8ms4t322jq3ms1b49rh0000gn/T/ipykernel_5613/3318711153.py:3: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(filepath)\n"
     ]
    }
   ],
   "source": [
    "data_name = \"arXiv0_tags\"\n",
    "data = load_data(f\"data/{data_name}.csv\", 2000)\n",
    "text = data[\"text\"]\n",
    "tags = data[\"tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing sentence-transformers/all-MiniLM-L6-v2 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch:   Solid-state superi...: 100%|██████████| 63/63 [01:13<00:00,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"minilm\"\n",
    "minilm_embeddings = emb.process_embeddings(text, model_name)\n",
    "save_to_pickle(minilm_embeddings, \"embeddings/arXiv0_minilm_mean_n2000.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing sentence-transformers/all-mpnet-base-v2 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch:   Solid-state superi...: 100%|██████████| 63/63 [06:40<00:00,  6.36s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"mpnet\"\n",
    "mpnet_embeddings = emb.process_embeddings(text, model_name)\n",
    "save_to_pickle(mpnet_embeddings, \"embeddings/arXiv0_mpnet_mean_n2000.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Nomic Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "Processing batch:   Solid-state superi...: 100%|██████████| 63/63 [10:09<00:00,  9.68s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"nomic\"\n",
    "nomic_embeddings = emb.process_embeddings(text, model_name)\n",
    "save_to_pickle(nomic_embeddings, \"embeddings/arXiv0_nomic_mean_n2000.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing AllenAI Specter Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch:   Solid-state superi...: 100%|██████████| 63/63 [08:09<00:00,  7.77s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"specter\"\n",
    "specter_embeddings = emb.process_embeddings(text, model_name)\n",
    "save_to_pickle(specter_embeddings, \"embeddings/arXiv0_specter_mean_n2000.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Google BERT Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch:   Solid-state superi...: 100%|██████████| 63/63 [10:42<00:00, 10.19s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert\"\n",
    "bert_embeddings = emb.process_embeddings(text, model_name)\n",
    "save_to_pickle(bert_embeddings, \"embeddings/arXiv0_bert_mean_n2000.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Word2Vec Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch:     S...: 100%|██████████| 63/63 [00:01<00:00, 32.03it/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"word2vec\"\n",
    "word2vec_embeddings = emb.process_embeddings(text, model_name)\n",
    "save_to_pickle(word2vec_embeddings, \"embeddings/arXiv0_word2vec_mean_n2000.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
