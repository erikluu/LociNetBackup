{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Experiment Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erikluu/Documents/Poly/Thesis/LociNet/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "import src.utils as utils\n",
    "import src.embeddings as emb\n",
    "import src.similarity as ss\n",
    "import src.edge_constructors as edge\n",
    "import src.aggregation as agg\n",
    "import src.clustering as cluster\n",
    "import src.graph_construction as gc\n",
    "import src.pipeline as pipe\n",
    "import src.metrics as m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each graph is labeled with the following components:\n",
    "\n",
    "- **Data**: Description of the dataset or source\n",
    "- **Embedding Model**: Type of embedding model used, optionally followed by parameters\n",
    "- **Edge Assignment**: Method of edge assignment, optionally followed by parameters\n",
    "- **Aggergator**: Method of aggregating embeddings. Used for cluster nodes.\n",
    "- **Clustering Method**: Method used for clustering, optionally followed by parameters\n",
    "- **Small World**: Method used for assigning new edges between nodes.\n",
    "\n",
    "Example:\n",
    "- **Data**: interview\n",
    "- **Embedding Model**: all-MiniLM-L6-v2\n",
    "- **Comparison Metric**: cosine\n",
    "- **Edge Assignment**: knn2\n",
    "- **Aggregator**: mean_pooling\n",
    "- **Clusterer**: None\n",
    "- **Small World**: None\n",
    "\n",
    "`interview_all-MiniLM-L6-v2_cosine_knn2_mean_x_x.pickle`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath, n=None):\n",
    "    assert filepath[-4:] == \".csv\", \"Must be a .csv file\"\n",
    "    data = pd.read_csv(filepath)\n",
    "    if n:\n",
    "        data = data.head(n)\n",
    "    attrs = {\n",
    "        \"titles\": data[\"title\"].tolist(),\n",
    "        \"text\": data[\"text\"].tolist(),\n",
    "        \"tags\": data[\"tags\"].apply(ast.literal_eval).tolist(),\n",
    "        \"ids\": data.index.tolist()\n",
    "    }\n",
    "\n",
    "    if \"simplified_tags\" in data.columns:\n",
    "        attrs[\"simplified_tags\"] = data[\"simplified_tags\"].apply(ast.literal_eval).tolist()\n",
    "\n",
    "    return attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data: interview_prep.csv\n",
    "\n",
    "My Study.com presentation prep: [[write-up](https://docs.google.com/document/d/14gn6bOk_FW9pkEgEESlip1B_zXMUKVgQeM3tP_fTx5A/edit?usp=sharing)]\n",
    "- Split by section headers\n",
    "- Placeholder tags: [\"haha\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(\"data/interview_prep.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings: sentence-transformers/all-MiniLM-L6-v2\n",
    "Metric: Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erikluu/Documents/Poly/Thesis/LociNet/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Processing batch: This is a project I ...: 100%|██████████| 1/1 [00:02<00:00,  2.42s/it]\n",
      "Similarity batch: 0/14: 100%|██████████| 1/1 [00:00<00:00, 352.26it/s]\n"
     ]
    }
   ],
   "source": [
    "model_id = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "tokenizer, model = emb.initialize_embedding_model(model_id)\n",
    "embeddings = emb.batch_embeddings(data[\"text\"], tokenizer, model) # pyright: ignore\n",
    "similarity_scores = ss.batch_similarity_scores(embeddings, metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 1\n",
    "- similarity metric: cosine\n",
    "- edge constructor: knn (k=2)\n",
    "- aggregator: mean pooling\n",
    "- clusterer: None\n",
    "- small world: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Similarity batch: 0/14: 100%|██████████| 1/1 [00:00<00:00, 432.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# make graph\n",
    "pickle_name = \"graphs/interview_all-MiniLM-L6-v2_cosine_knn2_mean_x_x.pickle\"\n",
    "knn_edge_constructor = lambda sim_mat, ids: edge.knn(sim_mat, ids, k=2)\n",
    "G = pipe.connect_directly(embeddings, similarity_scores, data[\"ids\"],\n",
    "                          similarity_metric=\"cosine\",\n",
    "                          edge_constructor_f=knn_edge_constructor,\n",
    "                          aggregator_f=agg.mean_pooling,\n",
    "                          titles=data[\"titles\"], tags=data[\"tags\"])\n",
    "utils.save_graph_to_pickle(G, pickle_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn to json\n",
    "encoding_f = lambda x: utils.pca(x, n_components=5)\n",
    "utils.pickle_to_json(pickle_name, encoding_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 2\n",
    "- similarity metric: cosine\n",
    "- edge constructor: knn (k=2)\n",
    "- aggregator: mean pooling\n",
    "- clusterer: None\n",
    "- small world: Watts-Strogatz (p=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Similarity batch: 0/14: 100%|██████████| 1/1 [00:00<00:00, 476.19it/s]\n",
      "Watts-Strogatz: : 14it [00:00, 1221.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# make graph\n",
    "pickle_name = \"graphs/interview_all-MiniLM-L6-v2_cosine_knn2_mean_x_watts.pickle\"\n",
    "knn_edge_constructor = lambda sim_mat, ids: edge.knn(sim_mat, ids, k=2)\n",
    "G = pipe.connect_directly(embeddings, similarity_scores, data[\"ids\"],\n",
    "                          similarity_metric=\"cosine\",\n",
    "                          edge_constructor_f=knn_edge_constructor,\n",
    "                          aggregator_f=agg.mean_pooling,\n",
    "                          titles=data[\"titles\"], tags=data[\"tags\"])\n",
    "G = gc.watts_strogatz(G, similarity_scores, p=0.2, seed=42)\n",
    "utils.save_graph_to_pickle(G, pickle_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_f = lambda x: utils.pca(x, n_components=5)\n",
    "utils.pickle_to_json(pickle_name, encoding_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 3\n",
    "- similarity metric: cosine\n",
    "- edge constructor: knn (k=2)\n",
    "- aggregator: mean pooling\n",
    "- clusterer: kmeans (n=2)\n",
    "- small world: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Similarity batch: 0/10: 100%|██████████| 1/1 [00:00<00:00, 23.04it/s]\n",
      "Similarity batch: 0/4: 100%|██████████| 1/1 [00:00<00:00, 443.65it/s]\n",
      "Similarity batch: 0/3: 100%|██████████| 1/1 [00:00<00:00, 311.45it/s]\n"
     ]
    }
   ],
   "source": [
    "pickle_name = \"graphs/interview_all-MiniLM-L6-v2_cosine_knn2_mean_kmeans2_x.pickle\"\n",
    "knn_edge_constructor = lambda sim_mat, ids: edge.knn(sim_mat, ids, k=2)\n",
    "kmeans_clusterer = lambda embeddings: cluster.kmeans(embeddings, n_clusters=2)\n",
    "G = pipe.cluster_and_connect(embeddings, similarity_scores, data[\"ids\"],\n",
    "                             similarity_metric=\"cosine\",\n",
    "                             edge_constructor_f=knn_edge_constructor,\n",
    "                             clusterer_f=kmeans_clusterer,\n",
    "                             aggregator_f=agg.mean_pooling,\n",
    "                             titles=data[\"titles\"], tags=data[\"tags\"])\n",
    "utils.save_graph_to_pickle(G, pickle_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_f = lambda x: utils.pca(x, n_components=5)\n",
    "utils.pickle_to_json(pickle_name, encoding_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data: medium_1k_tags.csv\n",
    "\n",
    "Medium Articles: [huggingface dataset](https://huggingface.co/datasets/fabiochiu/medium-articles)\n",
    "- Blog post's tags must appear >1k times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(\"data/medium_1k_tags_simplified.csv\", n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings: sentence-transformers/all-MiniLM-L6-v2\n",
    "Metric: Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erikluu/Documents/Poly/Thesis/LociNet/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Processing batch: Our focus today will...: 100%|██████████| 4/4 [00:20<00:00,  5.09s/it]\n",
      "Similarity batch: 96/100: 100%|██████████| 4/4 [00:00<00:00, 76.28it/s]\n"
     ]
    }
   ],
   "source": [
    "model_id = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "tokenizer, model = emb.initialize_embedding_model(model_id)\n",
    "embeddings = emb.batch_embeddings(data[\"text\"], tokenizer, model) # pyright: ignore\n",
    "similarity_scores = ss.batch_similarity_scores(embeddings, metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 4\n",
    "- similarity metric: cosine\n",
    "- edge constructor: knn (k=3)\n",
    "- aggregator: mean pooling\n",
    "- clusterer: None\n",
    "- small world: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Similarity batch: 96/100: 100%|██████████| 4/4 [00:00<00:00, 210.39it/s]\n"
     ]
    }
   ],
   "source": [
    "pickle_name = \"graphs/medium1k_all-MiniLM-L6-v2_cosine_knn3_mean_x_x.pickle\"\n",
    "knn_edge_constructor = lambda sim_mat, ids: edge.knn(sim_mat, ids, k=3)\n",
    "G = pipe.connect_directly(embeddings, similarity_scores, data[\"ids\"],\n",
    "                          similarity_metric=\"cosine\",\n",
    "                          edge_constructor_f=knn_edge_constructor,\n",
    "                          aggregator_f=agg.mean_pooling,\n",
    "                          titles=data[\"titles\"], tags=data[\"tags\"], simplified_tags=data[\"simplified_tags\"])\n",
    "utils.save_graph_to_pickle(G, pickle_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils as utils\n",
    "import src.metrics as m\n",
    "G = utils.load_graph_from_pickle(\"graphs/medium1k_all-MiniLM-L6-v2_cosine_knn3_mean_x_x.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mental Note Vol. 24\n",
      "Your Brain On Coronavirus\n",
      "Mind Your Nose\n",
      "The 4 Purposes of Dreams\n",
      "Surviving a Rod Through the Head\n",
      "Mentally, Young Adults Are Suffering Most From COVID\n",
      "How to Turn Your Popular Blog Series Into a Bestselling Book\n",
      "Dr Faisal Dar — Pioneer of Liver Transplantation in Pakistan\n",
      "Sunlight — The Natural Supplement For Our Mental Health\n",
      "Occam’s dice\n",
      "To Quickly Build Trust, Tell Your Origin Story\n",
      "Four Exercises to Strengthen Your Writing\n",
      "Facing Three Fundamental Coronavirus Fears\n",
      "For Creatives, Silence Isn’t Always Golden\n",
      "This 10-Minute Routine Will Increase Your Clarity And Creativity\n",
      "The Ted Talk That Changed My Life\n",
      "How to Make Your Day Job Support Your Art\n",
      "Exploring New York City Restaurants\n",
      "A Social Worker Offered Mormon Lingo to Me When I Was in Crisis, Told Me to Think Happy Thoughts, and Hung Up on Me — While I Was Still in Crisis\n",
      "An Effective Five-Step Process for Writing Captivating Headlines\n",
      "Loss Aversion — how fear influences customer choice\n",
      "The FDA Banned These Chemicals — and They’re Still Everywhere\n",
      "Can This Toxic Question Please Just Go Away?\n",
      "This is sloppy and hides intent if you ever reference it more\n",
      "Don’t Be a Writer, Be an Entrepreneur Who Writes\n",
      "What Should Systems Neuroscience Do Next? Voltage Imaging\n",
      "Why Writing Online Is Different\n",
      "Your Brand is What People Expect From You\n",
      "The Only Book About Writing You’ll Ever Need\n",
      "Tech Execs Face Congress: 9 Big Takeaways\n",
      "How to Be Productive and Creative in Times of Panic\n",
      "Quora Overview\n",
      "The Simple Formula For Becoming A Better Writer\n",
      "AI creating Human-Looking Images and Tracking Artificial Intelligence Programs in 2020\n",
      "Evolution doesn’t give a damn what you think a brain region is called\n",
      "Is It Fear You Feel, Or Anxiety?\n",
      "Avoid Clickbait: Headline Techniques Used by Six Reputable Media Sites\n",
      "How a Single Medium Article Received 100,000 Views\n",
      "A Marketing Guide for Introverts\n",
      "How to Add Upscribe Forms to Your Medium Posts\n",
      "The Power of Sleep in Learning: Mind-Blowing Science\n",
      "AI analyzes language to predict schizophrenia\n",
      "Should You Stay In Your Lane as a Writer?\n",
      "3 Marketing Strategies That Can Work Like Magic\n",
      "How The Media Can Prevent Copycat Suicides\n",
      "Thoughts on a medical mystery\n",
      "All the Love you do not see\n",
      "Allow Yourself To Be Creative\n",
      "How To Rewire Your Brain To Succeed During Uncertain Times\n",
      "Founders’ silent struggle — The biggest needs (Part 7)\n",
      "Walking Is Underrated: The Unappreciated Complexity and Power of Walking\n",
      "The Sustainable Element-Technology Nexus that has Great Potential\n",
      "How To Write a Powerful Piece of Content in One Hour\n",
      "2 Habits That Underrate Your Voice’s Influence\n",
      "Food Cravings: Microscopic Puppetmasters Might Be Involved\n",
      "AI Diagnoses Alzheimer’s With More Than 95% Accuracy\n",
      "A not entirely serious future history of neuroscience\n",
      "The 3 Best Ways to Respond to Negative Comments on Your Articles\n",
      "How to Escape a Writers Slump in The Easiest Way Possible\n",
      "How Antibiotics Could Alter the Child’s Mind and Body Development\n",
      "2019: a lightly bamboozled review of the year in neuroscience\n",
      "Your Thoughts Are Not Original\n",
      "How a 77-Year-Old Theory Can Help You Write Wonderful Headlines\n",
      "Exploring Your Mobile App Business Idea\n",
      "How To Make Your Writing More Engaging\n",
      "How Much Sleep Do You Need?\n",
      "Mind Management, Not Time Management now available for pre-order\n",
      "Predicting The Protein Structures Using AI\n",
      "Do Headlines Really Make a Difference?\n",
      "Unleash the Potential of AI in Circular Economy: Businesses Potentials\n",
      "How to Write Something People Will Actually Read\n",
      "What It’s Like to Have an ADHD Brain\n",
      "Four Reasons You Won’t Make It as a Professional Writer\n",
      "5 Tactics to Keep Writing when No One is Reading Your Work\n",
      "5 Reasons Why You Find It Hard To Wake Up At Early Everyday\n",
      "Discover ILLUMINATION Writers\n",
      "Ecosystem restoration, reviving hope.\n",
      "Music Star Alex Boye Is Doing an Anti-Suicide Concert. The Former Member of the Mormon Tabernacle Choir Performed in an Anti-Gay Marriage Event. Does He Have Regrets?\n",
      "Datalake File Ingestion: From FTP to AWS S3\n",
      "Only 49% of Americans Plan to Get Vaccinated Against COVID-19. Yes, You Should Be That Shocked\n",
      "The Importance of Blank Space on Your Calendar\n",
      "A Goodbye to Golden Muzzles: Internal Dissent and the Cautionary Tale of Facebook\n",
      "Essential OpenCV Functions to Get You Started into Computer Vision\n",
      "Is All Writing Valuable Writing?\n",
      "How Writing 1000 Words a Day Changed my Life\n",
      "Anorexia Has A Bacterial Origin, Researchers Say\n",
      "Here Is A Creative Exercise in Futuristic Storytelling and Worldbuilding\n",
      "Tell Your Mood to F*ck Off, Push Your Mind Harder, and Create\n",
      "It’s Now or Never for a Green New Deal\n",
      "Founders’ silent struggle — Overcoming setbacks (Part 6)\n",
      "Lockdown and Chronic Depression are a Double Jeopardy\n",
      "Federated Querying across Relational, Non-relational, Object, and Custom Data Sources using Amazon Athena\n",
      "“Holy”: Jamila Woods’s HEAVN Finds Spiritual Freedom in Solitude\n",
      "How Google and Its Geeks Nudge Each Other to Sustainability\n",
      "J.K. Rowling’s Advice For Writers With Big Dreams\n",
      "F. Scott Fitzgerald on How to Write Masterful Dialogue\n",
      "How are Big Tech Companies Dominating the Markets in the Global Arena?\n",
      "‘Am I Just Lazy?’\n",
      "Walk, Scrub, Shower!\n",
      "People Are Still Vacationing in the Middle of a Pandemic\n",
      "ClusterNode_b7847d17e2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_tags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Poly/Thesis/LociNet/src/metrics.py:42\u001b[0m, in \u001b[0;36maggregate_metrics\u001b[0;34m(graph, sample_size, depth, n_tags)\u001b[0m\n\u001b[1;32m     40\u001b[0m avg_edge_dist_within_cluster \u001b[38;5;241m=\u001b[39m metric_for_each_cluster(average_edge_distance_within_cluster, graph, cluster_ids)\n\u001b[1;32m     41\u001b[0m avg_dist_to_same_tags \u001b[38;5;241m=\u001b[39m average_distance_to_nodes_with_same_tags(graph, sample_size)\n\u001b[0;32m---> 42\u001b[0m tag_variation_bfs_result \u001b[38;5;241m=\u001b[39m \u001b[43mtag_variation_bfs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m tag_overlap_result \u001b[38;5;241m=\u001b[39m tag_overlap_summary(graph, get_n_unique_tags(graph, n_tags))\n\u001b[1;32m     46\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMetric\u001b[39m\u001b[38;5;124m'\u001b[39m: [\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage Embedding Distance Within Cluster\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m     ]\n\u001b[1;32m     63\u001b[0m }\n",
      "File \u001b[0;32m~/Documents/Poly/Thesis/LociNet/src/metrics.py:184\u001b[0m, in \u001b[0;36mtag_variation_bfs\u001b[0;34m(graph, n_nodes, depth)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# Perform BFS up to a specified depth\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m current_node, current_depth \u001b[38;5;129;01min\u001b[39;00m nx\u001b[38;5;241m.\u001b[39mbfs_edges(graph, source\u001b[38;5;241m=\u001b[39mnode_id, depth_limit\u001b[38;5;241m=\u001b[39mdepth):\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcurrent_depth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m:\n\u001b[1;32m    185\u001b[0m         current_node_data \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mnodes[current_node]\n\u001b[1;32m    186\u001b[0m         visited_tags\u001b[38;5;241m.\u001b[39mextend(current_node_data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m'\u001b[39m, []))\n",
      "\u001b[0;31mTypeError\u001b[0m: '<=' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "m.aggregate_metrics(G, sample_size=10, depth=2, n_tags=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_f = lambda x: utils.pca(x, n_components=5)\n",
    "utils.pickle_to_json(pickle_name, encoding_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 5\n",
    "- similarity metric: cosine\n",
    "- edge constructor: knn (k=3)\n",
    "- aggregator: mean pooling\n",
    "- clusterer: kmeans (n=5)\n",
    "- small world: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Similarity batch: 0/20: 100%|██████████| 1/1 [00:00<00:00, 29.26it/s]\n",
      "Similarity batch: 0/29: 100%|██████████| 1/1 [00:00<00:00, 38.58it/s]\n",
      "Similarity batch: 0/30: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s]\n",
      "Similarity batch: 0/9: 100%|██████████| 1/1 [00:00<00:00, 696.38it/s]\n",
      "Similarity batch: 0/12: 100%|██████████| 1/1 [00:00<00:00, 31.19it/s]\n",
      "Similarity batch: 0/6: 100%|██████████| 1/1 [00:00<00:00, 512.56it/s]\n"
     ]
    }
   ],
   "source": [
    "pickle_name = \"graphs/medium1k_all-MiniLM-L6-v2_cosine_knn3_mean_kmeans5_x.pickle\"\n",
    "knn_edge_constructor = lambda sim_mat, ids: edge.knn(sim_mat, ids, k=3)\n",
    "kmeans_clusterer = lambda embeddings: cluster.kmeans(embeddings, n_clusters=5)\n",
    "G = pipe.cluster_and_connect(embeddings, similarity_scores, data[\"ids\"],\n",
    "                             similarity_metric=\"cosine\",\n",
    "                             edge_constructor_f=knn_edge_constructor,\n",
    "                             clusterer_f=kmeans_clusterer,\n",
    "                             aggregator_f=agg.mean_pooling,\n",
    "                             titles=data[\"titles\"], tags=data[\"tags\"], simplified_tags=data[\"simplified_tags\"])\n",
    "utils.save_graph_to_pickle(G, pickle_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_f = lambda x: utils.pca(x, n_components=5)\n",
    "utils.pickle_to_json(pickle_name, encoding_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 6\n",
    "- similarity metric: cosine\n",
    "- edge constructor: knn (k=3)\n",
    "- aggregator: mean pooling\n",
    "- clusterer: kmeans (n=20)\n",
    "- small world: None\n",
    "\n",
    "What happens when we use the same number of clusters as there are unique tags? Greater than? Less than?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Similarity batch: 0/3: 100%|██████████| 1/1 [00:00<00:00, 283.86it/s]\n",
      "Similarity batch: 0/17: 100%|██████████| 1/1 [00:00<00:00, 73.96it/s]\n",
      "Similarity batch: 0/4: 100%|██████████| 1/1 [00:00<00:00, 257.34it/s]\n",
      "Similarity batch: 0/1: 100%|██████████| 1/1 [00:00<00:00, 474.36it/s]\n",
      "Similarity batch: 0/15: 100%|██████████| 1/1 [00:00<00:00, 31.57it/s]\n",
      "Similarity batch: 0/4: 100%|██████████| 1/1 [00:00<00:00, 646.37it/s]\n",
      "Similarity batch: 0/1: 100%|██████████| 1/1 [00:00<00:00, 407.69it/s]\n",
      "Similarity batch: 0/4: 100%|██████████| 1/1 [00:00<00:00, 374.96it/s]\n",
      "Similarity batch: 0/10: 100%|██████████| 1/1 [00:00<00:00, 23.96it/s]\n",
      "Similarity batch: 0/4: 100%|██████████| 1/1 [00:00<00:00, 809.55it/s]\n",
      "Similarity batch: 0/6: 100%|██████████| 1/1 [00:00<00:00, 488.28it/s]\n",
      "Similarity batch: 0/1: 100%|██████████| 1/1 [00:00<00:00, 786.19it/s]\n",
      "Similarity batch: 0/12: 100%|██████████| 1/1 [00:00<00:00, 596.63it/s]\n",
      "Similarity batch: 0/5: 100%|██████████| 1/1 [00:00<00:00, 836.69it/s]\n",
      "Similarity batch: 0/3: 100%|██████████| 1/1 [00:00<00:00, 871.82it/s]\n",
      "Similarity batch: 0/2: 100%|██████████| 1/1 [00:00<00:00, 560.29it/s]\n",
      "Similarity batch: 0/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Similarity batch: 0/1: 100%|██████████| 1/1 [00:00<00:00, 914.19it/s]\n",
      "Similarity batch: 0/1: 100%|██████████| 1/1 [00:00<00:00, 737.52it/s]\n",
      "Similarity batch: 0/1: 100%|██████████| 1/1 [00:00<00:00, 818.88it/s]\n",
      "Similarity batch: 0/5: 100%|██████████| 1/1 [00:00<00:00, 358.67it/s]\n",
      "Similarity batch: 0/21: 100%|██████████| 1/1 [00:00<00:00, 441.32it/s]\n"
     ]
    }
   ],
   "source": [
    "pickle_name = \"graphs/medium1k_all-MiniLM-L6-v2_cosine_knn3_mean_kmeans20_x.pickle\"\n",
    "knn_edge_constructor = lambda sim_mat, ids: edge.knn(sim_mat, ids, k=3)\n",
    "kmeans_clusterer = lambda embeddings: cluster.kmeans(embeddings, n_clusters=20)\n",
    "G = pipe.cluster_and_connect(embeddings, similarity_scores, data[\"ids\"],\n",
    "                             similarity_metric=\"cosine\",\n",
    "                             edge_constructor_f=knn_edge_constructor,\n",
    "                             clusterer_f=kmeans_clusterer,\n",
    "                             aggregator_f=agg.mean_pooling,\n",
    "                             titles=data[\"titles\"], tags=data[\"tags\"], simplified_tags=data[\"simplified_tags\"])\n",
    "utils.save_graph_to_pickle(G, pickle_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_f = lambda x: utils.pca(x, n_components=5)\n",
    "utils.pickle_to_json(pickle_name, encoding_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 7\n",
    "- similarity metric: cosine\n",
    "- edge constructor: knn (k=3)\n",
    "- aggregator: mean pooling\n",
    "- clusterer: kmeans (n=5)\n",
    "- small world: Watts Strogatz (p=0.2)\n",
    "\n",
    "What happens when we use the same number of clusters as there are unique tags? Greater than? Less than?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Similarity batch: 0/20: 100%|██████████| 1/1 [00:00<00:00, 16.86it/s]\n",
      "Similarity batch: 0/29: 100%|██████████| 1/1 [00:00<00:00, 25.17it/s]\n",
      "Similarity batch: 0/30:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Similarity batch: 0/30: 100%|██████████| 1/1 [00:00<00:00, 27.30it/s]\n",
      "Similarity batch: 0/9: 100%|██████████| 1/1 [00:00<00:00, 780.77it/s]\n",
      "Similarity batch: 0/12: 100%|██████████| 1/1 [00:00<00:00, 204.93it/s]\n",
      "Similarity batch: 0/6: 100%|██████████| 1/1 [00:00<00:00, 411.00it/s]\n",
      "Watts-Strogatz: : 100it [00:00, 1634.01it/s]\n"
     ]
    }
   ],
   "source": [
    "pickle_name = \"graphs/medium1k_all-MiniLM-L6-v2_cosine_knn3_mean_kmeans5_watts20.pickle\"\n",
    "knn_edge_constructor = lambda sim_mat, ids: edge.knn(sim_mat, ids, k=3)\n",
    "kmeans_clusterer = lambda embeddings: cluster.kmeans(embeddings, n_clusters=5)\n",
    "G = pipe.cluster_and_connect(embeddings, similarity_scores, data[\"ids\"],\n",
    "                             similarity_metric=\"cosine\",\n",
    "                             edge_constructor_f=knn_edge_constructor,\n",
    "                             clusterer_f=kmeans_clusterer,\n",
    "                             aggregator_f=agg.mean_pooling,\n",
    "                             titles=data[\"titles\"], tags=data[\"tags\"], simplified_tags=data[\"simplified_tags\"])\n",
    "G = gc.watts_strogatz(G, similarity_scores, p=0.2, seed=42)\n",
    "utils.save_graph_to_pickle(G, pickle_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_f = lambda x: utils.pca(x, n_components=5)\n",
    "utils.pickle_to_json(pickle_name, encoding_f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
